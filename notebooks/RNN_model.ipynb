{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dc09064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MIDI files found: 1630\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n02 K280.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n03 K281.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n04 K282.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n05 K283.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n06 K284.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n07 K309.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n08 K311.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n09 K310.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n10 K330.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n11 K331.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n12 K332.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n13 K333.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n14 K457.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n15 K593-494.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n16 K545.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n17 K547a.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n18 K570.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Piano Sonata n19 K576.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K19d Piano Sonata Duet.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K279 Piano sonata n01 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K279 Piano sonata n01 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K279 Piano sonata n01 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K280 Piano sonata n02 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K280 Piano sonata n02 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K280 Piano sonata n02 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K281 Piano Sonata n03 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K281 Piano Sonata n03 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K281 Piano Sonata n03 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K282 Piano Sonata n04 .mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K284 Piano Sonata n06 .mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K309 Piano Sonata n10 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K309 Piano Sonata n10 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K309 Piano Sonata n10 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K330 Piano Sonata n10 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K330 Piano Sonata n10 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K330 Piano Sonata n10 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K331 Piano Sonata n11 .mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K331 Piano sonata n11 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K332 Piano Sonata n12 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K332 Piano Sonata n12 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K332 Piano Sonata n12 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K333 Piano Sonata n13 .mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K333 Piano Sonata n13 1mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K333 Piano Sonata n13 2mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K333 Piano Sonata n13 3mov.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K357 Piano Sonata 4 Hands.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K358 Piano Sonata 4 Hands.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K381 Piano Sonata 4 Hands.mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K457 Piano Sonata n14 .mid\n",
      "Composer: Mozart, File Path: ..\\data\\midi\\archive\\midiclassics\\Mozart\\Piano Sonatas\\Nueva carpeta\\K497 Piano Sonata 4 Hands.mid\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.int = int\n",
    "import pretty_midi\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# List of target composers\n",
    "target_compsers = ['Bach', 'Beethoven', 'Chopin', 'Mozart']\n",
    "\n",
    "# Folder containing the dataset\n",
    "dataset_folder = Path('../data/midi/archive/midiclassics')\n",
    "\n",
    "# Storing paths of MIDI files for each composer\n",
    "dataset = []\n",
    "\n",
    "# Avoid dublicate filenames\n",
    "seen_filenames = set()\n",
    "\n",
    "#Looping through each target composer folder\n",
    "for composer in target_compsers:\n",
    "    composer_folder = dataset_folder / composer\n",
    "\n",
    "    # Recursively find all MIDI files in all subfolders in the composer's folder\n",
    "    for file_path in composer_folder.rglob('*'): # Iterate over this subtree and yield all existing files\n",
    "        if file_path.suffix.lower() in ['.mid', '.midi']: # Only consider MIDI files\n",
    "            \n",
    "            # Check if the filename has already been seen\n",
    "            if file_path.name not in seen_filenames:\n",
    "                seen_filenames.add(file_path.name)\n",
    "                dataset.append((str(file_path), composer)) # Add the file path to the dataset\n",
    "\n",
    "# Check total files found \n",
    "print(f\"Total MIDI files found: {len(dataset)}\")\n",
    "\n",
    "# Display the first 10 file paths\n",
    "for path, composer in dataset[1500:1550]:\n",
    "    print(f\"Composer: {composer}, File Path: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7a6968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 398445658473397961\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------------\n",
    "# Function to parse one MIDI file (returns 6 features per note)\n",
    "def parse_midi_file(file_path):\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(file_path)\n",
    "        notes = []\n",
    "\n",
    "        # Get global tempo (default to 120 if not found)\n",
    "        tempo_changes = midi.get_tempo_changes()[1]\n",
    "        global_tempo = round(float(tempo_changes[0]) if len(tempo_changes) > 0 else 120.0, 2)\n",
    "\n",
    "        # Get instrument notes (skip drums)\n",
    "        for instrument in midi.instruments:\n",
    "            if not instrument.is_drum:\n",
    "                instrument_notes = instrument.notes\n",
    "                break\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        # Sort notes by start time\n",
    "        instrument_notes.sort(key=lambda n: n.start)\n",
    "        prev_start = 0.0\n",
    "\n",
    "        for note in instrument_notes:\n",
    "            pitch = note.pitch  # MIDI number (0–127)\n",
    "            duration = round(note.end - note.start, 4)  # in seconds\n",
    "            delta_time = round(note.start - prev_start, 4)  # time from previous note\n",
    "            velocity = note.velocity  # note strength\n",
    "\n",
    "            # Is part of a chord? (same start time as another note)\n",
    "            is_chord = int(any(\n",
    "                abs(note.start - other.start) < 0.01 and note.pitch != other.pitch\n",
    "                for other in instrument_notes\n",
    "            ))\n",
    "\n",
    "            prev_start = note.start\n",
    "            notes.append([pitch, duration, delta_time, velocity, global_tempo, is_chord])\n",
    "\n",
    "        return notes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 2: Parse all files in dataset\n",
    "sequence_length = 300  # Use 300-note (I used sequences =  100 at first try) \n",
    "parsed_sequences_300 = []\n",
    "labels_300 = []\n",
    "\n",
    "for path, composer in tqdm(dataset, desc=\"Parsing MIDI files (300 tokens)\"):\n",
    "    sequence = parse_midi_file(path)\n",
    "\n",
    "    # Pad or truncate to 300 notes per song\n",
    "    if len(sequence) > sequence_length:\n",
    "        sequence = sequence[:sequence_length]\n",
    "    else:\n",
    "        pad_size = sequence_length - len(sequence)\n",
    "        sequence += [[0, 0.0, 0.0, 0, 120.0, 0]] * pad_size  # padding values\n",
    "\n",
    "    parsed_sequences_300.append(sequence)\n",
    "    labels_300.append(composer)\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 3: Convert to arrays\n",
    "X_300 = np.array(parsed_sequences_300, dtype=np.float32)\n",
    "y_300 = np.array(labels_300)\n",
    "\n",
    "# Step 4: Print shapes and preview\n",
    "print(\"Final dataset shapes (300 tokens, 6 features):\")\n",
    "print(f\"X_300 shape (songs, notes, features): {X_300.shape}\")\n",
    "print(f\"y_300 shape (labels): {y_300.shape}\")\n",
    "print(\"Sample row (first song, first 5 notes):\")\n",
    "print(X_300[0][:5])\n",
    "print(f\" Label: {y_300[0]}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 5: Save for training\n",
    "with open(\"parsed_midi_lstm_ready_300tokens_6features.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'X': X_300, 'y': y_300}, f)\n",
    "\n",
    "print(\"Saved parsed data to 'parsed_midi_lstm_ready_300tokens_6features.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13680f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes: X_300 = (1630, 300, 6), y_300 = (1630,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the parsed MIDI dataset\n",
    "with open(\"parsed_midi_lstm_ready_300tokens_6features.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_300 = data['X']\n",
    "y_300 = data['y']\n",
    "\n",
    "print(f\"Loaded shapes: X_300 = {X_300.shape}, y_300 = {y_300.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8413be14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete.\n",
      "Sample normalized input (first row):\n",
      "[[ 0.41732284 -0.31523398 -0.13586776  0.23622048  0.5         0.        ]\n",
      " [ 0.4488189  -0.31523398 -0.0850317   0.23622048  0.5         0.        ]\n",
      " [ 0.47244096 -0.31523398 -0.0850317   0.23622048  0.5         0.        ]\n",
      " [ 0.511811   -0.31523398 -0.0850317   0.23622048  0.5         0.        ]\n",
      " [ 0.54330707 -0.31523398 -0.0850317   0.23622048  0.5         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input X (shape: num_samples, 100, 6)\n",
    "X_norm = np.copy(X_300)  \n",
    "\n",
    "# Feature 0: pitch (0–127) → scale to [0,1]\n",
    "X_norm[:, :, 0] = X_norm[:, :, 0] / 127.0\n",
    "\n",
    "# Feature 1: duration (seconds) → z-score normalization\n",
    "dur_mean = X_norm[:, :, 1].mean()\n",
    "dur_std = X_norm[:, :, 1].std()\n",
    "X_norm[:, :, 1] = (X_norm[:, :, 1] - dur_mean) / (dur_std + 1e-6)\n",
    "\n",
    "# Feature 2: delta_time → z-score normalization\n",
    "delta_mean = X_norm[:, :, 2].mean()\n",
    "delta_std = X_norm[:, :, 2].std()\n",
    "X_norm[:, :, 2] = (X_norm[:, :, 2] - delta_mean) / (delta_std + 1e-6)\n",
    "\n",
    "# Feature 3: velocity (0–127) → scale to [0,1]\n",
    "X_norm[:, :, 3] = X_norm[:, :, 3] / 127.0\n",
    "\n",
    "# Feature 4: tempo (common range: ~60–240 bpm) → scale to [0,1] using 240 as max\n",
    "X_norm[:, :, 4] = X_norm[:, :, 4] / 240.0\n",
    "\n",
    "# Feature 5: is_chord → already 0 or 1, keep unchanged\n",
    "# No action needed\n",
    "\n",
    "print(\"Normalization complete.\")\n",
    "print(\"Sample normalized input (first row):\")\n",
    "print(X_norm[0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a505ff",
   "metadata": {},
   "source": [
    "### Ignoring balacing data for now to find a proper way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7a0b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# # Set your token budget (e.g., 13000 tokens per composer)\n",
    "# MAX_TOKENS_PER_COMPOSER = 13000\n",
    "\n",
    "# # Group normalized sequences by composer\n",
    "# composer_to_sequences = defaultdict(list)\n",
    "# for seq, composer in zip(X_norm, y_300):  # Use normalized data and correct labels\n",
    "#     composer_to_sequences[composer].append(seq)\n",
    "\n",
    "# # ⚖ Select sequences to match max token count per composer\n",
    "# selected_sequences = []\n",
    "# selected_labels = []\n",
    "\n",
    "# for composer, sequences in composer_to_sequences.items():\n",
    "#     np.random.shuffle(sequences)  # Shuffle for randomness\n",
    "#     token_count = 0\n",
    "#     for seq in sequences:\n",
    "#         token_count += len(seq)  # Each seq has 300 tokens (notes)\n",
    "#         if token_count > MAX_TOKENS_PER_COMPOSER:\n",
    "#             break\n",
    "#         selected_sequences.append(seq)\n",
    "#         selected_labels.append(composer)\n",
    "\n",
    "# # Convert to NumPy arrays\n",
    "# X_balanced = np.array(selected_sequences, dtype=np.float32)\n",
    "# y_balanced = np.array(selected_labels)\n",
    "\n",
    "# # Print result summary\n",
    "# print(\"After token-based balancing:\")\n",
    "# for composer in np.unique(y_balanced):\n",
    "#     count = np.sum(y_balanced == composer)\n",
    "#     print(f\"{composer}: {count} sequences (≈ {count * 300} tokens)\")\n",
    "\n",
    "# print(f\"X_balanced shape: {X_balanced.shape}\")\n",
    "# print(f\"y_balanced shape: {y_balanced.shape}\")\n",
    "\n",
    "# #  Save the balanced dataset\n",
    "# with open(\"parsed_midi_lstm_balanced_300tokens_norm.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({'X': X_balanced, 'y': y_balanced}, f)\n",
    "\n",
    "# print(\" Saved balanced dataset to 'parsed_midi_lstm_balanced_300tokens_norm.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "635300d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "0: Bach\n",
      "1: Beethoven\n",
      "2: Chopin\n",
      "3: Mozart\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Encode the balanced labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_300)  # Convert to integer labels: [0,1,2,3]\n",
    "y_onehot = to_categorical(y_encoded)  # Convert to one-hot format: [[1,0,0,0], ...]\n",
    "\n",
    "# See label mapping\n",
    "print(\"Label Mapping:\")\n",
    "for i, name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e556a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Masking, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(300, 6))) \n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ca05c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c98ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "0: Bach\n",
      "1: Beethoven\n",
      "2: Chopin\n",
      "3: Mozart\n",
      "Train shape: (1304, 300, 6), Validation shape: (326, 300, 6)\n",
      "Epoch 1/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - accuracy: 0.5958 - loss: 1.0242 - val_accuracy: 0.6411 - val_loss: 0.8588\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.6633 - loss: 0.8788 - val_accuracy: 0.6779 - val_loss: 0.8474\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.6486 - loss: 0.8857 - val_accuracy: 0.6748 - val_loss: 0.8065\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.6424 - loss: 0.8511 - val_accuracy: 0.6871 - val_loss: 0.8047\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.7013 - loss: 0.7776 - val_accuracy: 0.6748 - val_loss: 0.8119\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.6776 - loss: 0.7997 - val_accuracy: 0.7209 - val_loss: 0.7703\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.6753 - loss: 0.7856 - val_accuracy: 0.7086 - val_loss: 0.7767\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.6890 - loss: 0.7619 - val_accuracy: 0.6718 - val_loss: 0.7891\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.6640 - loss: 0.7992 - val_accuracy: 0.6933 - val_loss: 0.7893\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.6924 - loss: 0.7576 - val_accuracy: 0.6810 - val_loss: 0.7716\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.6770 - loss: 0.7535 - val_accuracy: 0.6840 - val_loss: 0.7556\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.6719 - loss: 0.7382 - val_accuracy: 0.6810 - val_loss: 0.7967\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.6988 - loss: 0.7503 - val_accuracy: 0.6595 - val_loss: 0.7721\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7133 - loss: 0.7358 - val_accuracy: 0.6902 - val_loss: 0.7768\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.6920 - loss: 0.7621 - val_accuracy: 0.6902 - val_loss: 0.7547\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.6916 - loss: 0.7503 - val_accuracy: 0.6902 - val_loss: 0.7493\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.7052 - loss: 0.7309 - val_accuracy: 0.7055 - val_loss: 0.7440\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.7111 - loss: 0.7204 - val_accuracy: 0.7086 - val_loss: 0.7276\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.7221 - loss: 0.7106 - val_accuracy: 0.6963 - val_loss: 0.7640\n",
      "Epoch 20/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.6843 - loss: 0.7341 - val_accuracy: 0.6687 - val_loss: 0.7658\n",
      "Epoch 21/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - accuracy: 0.7035 - loss: 0.7175 - val_accuracy: 0.6963 - val_loss: 0.7145\n",
      "Epoch 22/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7149 - loss: 0.7055 - val_accuracy: 0.7025 - val_loss: 0.7124\n",
      "Epoch 23/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - accuracy: 0.7214 - loss: 0.6895 - val_accuracy: 0.7025 - val_loss: 0.7101\n",
      "Epoch 24/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.7273 - loss: 0.6532 - val_accuracy: 0.7178 - val_loss: 0.6961\n",
      "Epoch 25/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.7177 - loss: 0.6736 - val_accuracy: 0.7147 - val_loss: 0.6930\n",
      "Epoch 26/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 0.6665 - val_accuracy: 0.7209 - val_loss: 0.6936\n",
      "Epoch 27/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7331 - loss: 0.6543 - val_accuracy: 0.7055 - val_loss: 0.7072\n",
      "Epoch 28/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.7318 - loss: 0.6388 - val_accuracy: 0.7117 - val_loss: 0.7130\n",
      "Epoch 29/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7121 - loss: 0.7076 - val_accuracy: 0.6963 - val_loss: 0.7331\n",
      "Epoch 30/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.7103 - loss: 0.7465 - val_accuracy: 0.7147 - val_loss: 0.7179\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y_onehot, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     epochs=50,\n",
    "#                     batch_size=32)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 1: Encode the balanced labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_300)  # Convert to integer labels: [0,1,2,3]\n",
    "y_onehot = to_categorical(y_encoded)  # Convert to one-hot format: [[1,0,0,0], ...]\n",
    "\n",
    "# Optional: See label mapping\n",
    "print(\"Label Mapping:\")\n",
    "for i, name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {name}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 2: Train/Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_300, y_onehot,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded  # stratify based on integer labels\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 3: Train your LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]  # Use early stopping to prevent overfitting\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84259a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f39158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7147\n",
      "Precision: 0.5045\n",
      "Recall   : 0.4853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Precision & Recall (macro for balanced view across all classes)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a511_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
